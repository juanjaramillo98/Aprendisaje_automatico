{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autores\n",
    "\n",
    "Juan Pablo Jaramillo Tobon CC 1216727112\n",
    "\n",
    "Daniel Alejandro Higuita Usuga CC 1152706601\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Los registros de viajes en taxi amarillo y verde incluyen campos que capturan fechas/horas de recogida y devolución, lugares de recogida y devolución, distancias de viaje, tarifas detalladas, tipos de tarifas, tipos de pago y recuentos de pasajeros informados por el conductor. Los datos utilizados en los conjuntos de datos adjuntos se recopilaron y proporcionaron a la Comisión de Taxis y Limusinas de Nueva York (TLC).\n",
    "\n",
    "El dataset posee 19 columnas de las cuales usaremos solo 4\n",
    "\n",
    "* tpep_pickup_datetime: fecha y hora de inicio de carrera\n",
    "* pickup_longitude: longitud geoespacial de recogida de la carrera\n",
    "* pickup_latitude: latitud geoespacial de recogida de la carrera\n",
    "* tip_amount: propina dejada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "\n",
    "El objetivo es la creacion de un modelo que permita la prediccion de la propina dejada por los usuarios dependiendo de el lugar y la hora donde se recoge la propina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de env variables \n",
    "# ==============================================================================\n",
    "import yaml\n",
    "with open('config.yaml') as f:\n",
    "    env_vars = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Almacenar en caché los resultados de funciones en el disco\n",
    "# ==============================================================================\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "\n",
    "# Gestion de librerias\n",
    "# ==============================================================================\n",
    "from importlib import reload\n",
    "\n",
    "\n",
    "# Matemáticas y estadísticas\n",
    "# ==============================================================================\n",
    "import math\n",
    "\n",
    "\n",
    "# Preparación de datos\n",
    "# ==============================================================================\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "#Separar los datos entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Escalar Variables\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "#Evaluación del modelo\n",
    "from sklearn import metrics\n",
    "#from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "#from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "#Creación de modelo\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "#configuracion de hiperparámetros\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Gráficos\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Configuración warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv2015_1 = pd.read_csv('data/yellow_tripdata_2015-01.csv')\n",
    "csv2015_2 = pd.read_csv('data/yellow_tripdata_2015-02.csv')\n",
    "csv2015_3 = pd.read_csv('data/yellow_tripdata_2015-03.csv')\n",
    "\n",
    "df = pd.concat([csv2015_1,csv2015_2,csv2015_3],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparacion de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación de Columnas innecesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"tpep_pickup_datetime\",\"pickup_longitude\",\"pickup_latitude\",\"tip_amount\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimización del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if env_vars['minimize_dataset']:\n",
    "    particion = (100-0.1)/100\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df['reseña'],df['clasificacion'], test_size=particion, random_state=42)\n",
    "    df = pd.concat([y_train, X_train], axis=1)\n",
    "    del X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisión de Duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación de Duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Información del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('clasificacion').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento y normalizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraer del timestap minuto del dia, dia de la semana, mes del año\n",
    "\n",
    "# \"pickup_longitude\",\"pickup_latitude\",\"tip_amount\"\n",
    "\n",
    "df[\"dia\"] = df[\"tpep_pickup_datetime\"].dt.dayofweek\n",
    "df[\"mes\"] = df[\"tpep_pickup_datetime\"].dt.month\n",
    "df[\"minuto\"] = df[\"tpep_pickup_datetime\"].dt.minute + (df[\"tpep_pickup_datetime\"].dt.hour*60)\n",
    "\n",
    "df.drop(columns=['tpep_pickup_datetime'],inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_scaler = MinMaxScaler()\n",
    "month_scaler = MinMaxScaler()\n",
    "minute_scaler = MinMaxScaler()\n",
    "longitude_scaler = MinMaxScaler()\n",
    "latitude_scaler = MinMaxScaler()\n",
    "tip_scaler = MinMaxScaler()\n",
    "\n",
    "day_scaler.fit(df[\"dia\"])\n",
    "month_scaler.fit(df[\"mes\"])\n",
    "minute_scaler.fit(df[\"minuto\"])\n",
    "longitude_scaler.fit(df[\"pickup_longitude\"])\n",
    "latitude_scaler.fit(df[\"pickup_latitude\"])\n",
    "tip_scaler.fit(df[\"tip_amount\"])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
